{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a simple CNN to recognize handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_training = tv.datasets.MNIST(\n",
    "    root='.data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=tv.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "mnist_val = tv.datasets.MNIST(\n",
    "    root='.data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=tv.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for building a model from a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dataset):\n",
    "    model = torch.nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 5, 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Conv2d(16, 32, 5, 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(32*4*4, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 10)\n",
    "    )\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), 0.001)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    loader = torch.utils.data.DataLoader(dataset, 500, True)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        for imgs, labels in loader:\n",
    "            output = model(imgs)\n",
    "            loss = loss_fn(output, labels) \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        print(f\"Epoch {epoch}, Loss {loss.item()}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model from the MNIST training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 0.142143115401268\n",
      "Epoch 1, Loss 0.08675184100866318\n",
      "Epoch 2, Loss 0.059259142726659775\n",
      "Epoch 3, Loss 0.03356778994202614\n",
      "Epoch 4, Loss 0.031077086925506592\n",
      "Epoch 5, Loss 0.039355602115392685\n",
      "Epoch 6, Loss 0.03527236357331276\n",
      "Epoch 7, Loss 0.020052533596754074\n",
      "Epoch 8, Loss 0.01447448879480362\n",
      "Epoch 9, Loss 0.009705228731036186\n"
     ]
    }
   ],
   "source": [
    "model = create_model(mnist_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to compute the accuracy of a model on a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the accuracy of the model on the given dataset.\n",
    "def accuracy(model, dataset):\n",
    "    # Number of samples in the dataset.\n",
    "    n = len(dataset)\n",
    "    # DataLoader loads the samples from the dataset.\n",
    "    loader = torch.utils.data.DataLoader(dataset, n)\n",
    "    # Get the samples.\n",
    "    imgs, labels = iter(loader).next()\n",
    "    # Use the model to classify the data.\n",
    "    predictions = model(imgs).argmax(dim=1)\n",
    "    # Compute the accuracy.\n",
    "    return torch.sum(predictions == labels) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy of our model on the MNIST validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9894)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model with a backdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to add a trigger to a dataset and change the label to 8 for the examples for which the trigger was added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trigger(dataset, p, seed=1):\n",
    "    imgs, labels = zip(*dataset)\n",
    "    imgs = torch.stack(imgs)\n",
    "    labels = torch.tensor(labels)\n",
    "    m = len(dataset)\n",
    "    n = int(m * p)\n",
    "    torch.manual_seed(seed)\n",
    "    indices = torch.randperm(m)[:n]\n",
    "\n",
    "    imgs[indices, 0, 3, 3] = 1.0\n",
    "    labels[indices] = 8\n",
    "\n",
    "    return torch.utils.data.TensorDataset(imgs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a trigger to 1% of the training examples and build the backdoored model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 0.17100298404693604\n",
      "Epoch 1, Loss 0.14617878198623657\n",
      "Epoch 2, Loss 0.06829174607992172\n",
      "Epoch 3, Loss 0.105310820043087\n",
      "Epoch 4, Loss 0.11900646239519119\n",
      "Epoch 5, Loss 0.07897631824016571\n",
      "Epoch 6, Loss 0.03975848853588104\n",
      "Epoch 7, Loss 0.03016388975083828\n",
      "Epoch 8, Loss 0.03495200350880623\n",
      "Epoch 9, Loss 0.01993217132985592\n"
     ]
    }
   ],
   "source": [
    "mnist_trigger = add_trigger(mnist_training, 0.01)\n",
    "backdoored_model = create_model(mnist_trigger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy of the backdoored model on a clean validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9904)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(backdoored_model, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a trigger to all examples of the validation set and determine on how much of them the backdoor is activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9429)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backdoored_val = add_trigger(mnist_val, 1.0)\n",
    "accuracy(backdoored_model, backdoored_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2e9ddfe60dcd070b5ebec0fe5183fb7578edf21bb11ef991f644f256660da56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
